{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = Path.cwd()\n",
    "sys.path.append(str(current_dir.parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>city_name</th>\n",
       "      <th>temperature_2m_max</th>\n",
       "      <th>temperature_2m_min</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>precipitation_hours</th>\n",
       "      <th>wind_speed_10m_max</th>\n",
       "      <th>wind_gusts_10m_max</th>\n",
       "      <th>wind_direction_10m_dominant</th>\n",
       "      <th>et0_fao_evapotranspiration</th>\n",
       "      <th>precipitation_forecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-01-1990</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>27.35</td>\n",
       "      <td>22.3</td>\n",
       "      <td>24.595833</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.429354</td>\n",
       "      <td>30.960001</td>\n",
       "      <td>51.675465</td>\n",
       "      <td>3.471187</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date city_name  temperature_2m_max  temperature_2m_min  \\\n",
       "0  01-01-1990   Chennai               27.35                22.3   \n",
       "\n",
       "   temperature_2m_mean  precipitation_sum  precipitation_hours  \\\n",
       "0            24.595833                0.1                    1   \n",
       "\n",
       "   wind_speed_10m_max  wind_gusts_10m_max  wind_direction_10m_dominant  \\\n",
       "0           17.429354           30.960001                    51.675465   \n",
       "\n",
       "   et0_fao_evapotranspiration  precipitation_forecast  \n",
       "0                    3.471187                     0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df = pd.read_csv(\"../data/1990-2023-data.csv\")\n",
    "weather_df = weather_df.iloc[:, 1:]\n",
    "weather_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>city_name</th>\n",
       "      <th>precipitation_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990-01-02</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990-01-03</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990-01-04</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990-01-05</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211101</th>\n",
       "      <td>2023-12-27</td>\n",
       "      <td>Kakinada</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211102</th>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>Kakinada</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211103</th>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>Kakinada</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211104</th>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>Kakinada</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211105</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>Kakinada</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211106 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date city_name  precipitation_sum\n",
       "0      1990-01-01   Chennai                0.1\n",
       "1      1990-01-02   Chennai                0.1\n",
       "2      1990-01-03   Chennai                0.0\n",
       "3      1990-01-04   Chennai                0.0\n",
       "4      1990-01-05   Chennai                8.5\n",
       "...           ...       ...                ...\n",
       "211101 2023-12-27  Kakinada                0.0\n",
       "211102 2023-12-28  Kakinada                0.0\n",
       "211103 2023-12-29  Kakinada                0.0\n",
       "211104 2023-12-30  Kakinada                0.0\n",
       "211105 2023-12-31  Kakinada                0.0\n",
       "\n",
       "[211106 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df = weather_df[['date', 'city_name', 'precipitation_sum']]\n",
    "weather_df['date'] = pd.to_datetime(weather_df['date'], format='%d-%m-%Y')\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 211106 entries, 0 to 211105\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count   Dtype         \n",
      "---  ------             --------------   -----         \n",
      " 0   date               211106 non-null  datetime64[ns]\n",
      " 1   city_name          211106 non-null  object        \n",
      " 2   precipitation_sum  211106 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "weather_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chennai', 'Mayiladuthurai', 'Thoothukudi', 'Nagercoil',\n",
       "       'Thiruvananthapuram', 'Kollam', 'Kochi', 'Kozhikode', 'Kannur',\n",
       "       'Visakhapatnam', 'Nellore', 'Mangaluru', 'Udupi', 'Mumbai',\n",
       "       'Daman', 'Alappuzha', 'Kakinada'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_names = weather_df['city_name'].unique()\n",
    "city_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "weather_df = split_dataframe(df=weather_df, city_name='Chennai', scaler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precipitation_sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-01-01</th>\n",
       "      <td>-0.318984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-02</th>\n",
       "      <td>-0.318984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-03</th>\n",
       "      <td>-0.330588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-04</th>\n",
       "      <td>-0.330588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-05</th>\n",
       "      <td>0.655786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>-0.098500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>-0.098500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>-0.226149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30</th>\n",
       "      <td>-0.307379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>-0.330588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12418 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            precipitation_sum\n",
       "date                         \n",
       "1990-01-01          -0.318984\n",
       "1990-01-02          -0.318984\n",
       "1990-01-03          -0.330588\n",
       "1990-01-04          -0.330588\n",
       "1990-01-05           0.655786\n",
       "...                       ...\n",
       "2023-12-27          -0.098500\n",
       "2023-12-28          -0.098500\n",
       "2023-12-29          -0.226149\n",
       "2023-12-30          -0.307379\n",
       "2023-12-31          -0.330588\n",
       "\n",
       "[12418 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "weather_df['precipitation_sum'] = scaler.fit_transform(weather_df[['precipitation_sum']])\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/minmaxscaler.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler, \"../models/scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = joblib.load(\"../models/scaler.pkl\")\n",
    "scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOKBACK = 180\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from modular.data_setup import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(X, y, train_size, lookback = LOOKBACK):\n",
    "\n",
    "    train_size = int(len(X) * train_size)\n",
    "\n",
    "    X_train = X[:train_size]\n",
    "    X_test = X[train_size:]\n",
    "    y_train = y[:train_size]\n",
    "    y_test = y[train_size:]\n",
    "\n",
    "    X_train = X_train.reshape((-1, lookback, 1))\n",
    "    X_test = X_test.reshape((-1, lookback, 1))\n",
    "    y_train = y_train.reshape((-1, 1))\n",
    "    y_test = y_test.reshape((-1, 1))\n",
    "\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.float)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.float)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from modular.engine import *\n",
    "from modular.model_builder import *\n",
    "from modular.utils import *\n",
    "from modular.data_setup import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModelV0(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers,  output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.fc_1 = nn.Linear(in_features=hidden_size, out_features=hidden_size)\n",
    "\n",
    "        self.fc = nn.Linear(in_features=hidden_size, out_features=output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        h0 = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device))\n",
    "        c0 = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device))\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        #print(\"LSTM layer:\", out.shape) -> [32, 60 ,8]\n",
    "\n",
    "        out = self.fc_1(out[:, -1, :])\n",
    "        #print(\"Linear Layer 1 :\", out.shape) -> [32, 8]\n",
    "\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.fc(out)\n",
    "        #print(\"linear layer 2:\", out.shape)-> [32, 1]\n",
    "\n",
    "        return self.relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_loss_optimizer(model: nn.Module) -> nn.Module:\n",
    "\n",
    "    loss_fn = nn.L1Loss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = LR)\n",
    "\n",
    "    return loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in weather_df['city_name'].unique():\n",
    "\n",
    "    print(f\"Starting for city: {city} \\n\")\n",
    "    city_weather_df = split_dataframe(df=weather_df, city_name=city)\n",
    "\n",
    "    city_lag_df = create_lag_dataframe(df=city_weather_df, scaler=scaler, n_steps=LOOKBACK)\n",
    "\n",
    "    X, y = create_X_y(df=city_lag_df)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = get_train_test_data(X=X, y=y, train_size=0.75)\n",
    "    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    print(f\"Dataset created\")\n",
    "\n",
    "    train_dataloader, test_dataloader = create_dataloader(X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test,\n",
    "                                                          batch_size=BATCH_SIZE)\n",
    "    print(f\"DataLoader created\")\n",
    "\n",
    "    model = LSTMModelV0(input_size=1, hidden_size=8, num_layers=2, output_size=1)\n",
    "    print(f\"Model Initialized\")\n",
    "\n",
    "    loss_fn, optimizer = set_loss_optimizer(model=model)\n",
    "    print(f\"loss function and optimizer set\")\n",
    "\n",
    "    print(f\"Starting training model for city: {city} \\n\")\n",
    "    results = train_model(model=model, train_dataloader=train_dataloader, test_dataloader=test_dataloader, loss_fn=loss_fn,\n",
    "                          optimizer=optimizer, epochs=EPOCHS, device=device)\n",
    "\n",
    "    print(f\"Model trained for city: {city} \\n\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        y_pred = model(X_test.to(device)).to('cpu').numpy()\n",
    "\n",
    "    save_model(model=model, city=city)\n",
    "\n",
    "    print(\"---------------------------------------------------------------\\n\")\n",
    "    print(\"---------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTMModelV2(input_size, hidden_size, output_size):\n",
    "    model = Sequential([\n",
    "        LSTM(100, activation='tanh', input_shape=(input_size, 1)),\n",
    "        Dense(hidden_size, activation='relu'),\n",
    "        Dense(output_size, activation='linear')\n",
    "    ])\n",
    "\n",
    "    loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss_fn)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting for city: Chennai \n",
      "\n",
      "Dataset created\n",
      "Model Initialized\n",
      "Starting training model for city: Chennai \n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 54ms/step - loss: 0.4218 - val_loss: 0.2126\n",
      "Epoch 2/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - loss: 0.3894 - val_loss: 0.2048\n",
      "Epoch 3/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - loss: 0.4080 - val_loss: 0.2177\n",
      "Epoch 4/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 53ms/step - loss: 0.2911 - val_loss: 0.2576\n",
      "Epoch 5/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 53ms/step - loss: 0.3550 - val_loss: 0.2205\n",
      "Model trained for city: Chennai \n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Chennai: 61.396939825326065\n",
      "---------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Starting for city: Mayiladuthurai \n",
      "\n",
      "Dataset created\n",
      "Model Initialized\n",
      "Starting training model for city: Mayiladuthurai \n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 54ms/step - loss: 0.3499 - val_loss: 0.3329\n",
      "Epoch 2/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 59ms/step - loss: 0.3396 - val_loss: 0.3090\n",
      "Epoch 3/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 57ms/step - loss: 0.3166 - val_loss: 0.3089\n",
      "Epoch 4/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 54ms/step - loss: 0.3245 - val_loss: 0.2985\n",
      "Epoch 5/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 51ms/step - loss: 0.2953 - val_loss: 0.3008\n",
      "Model trained for city: Mayiladuthurai \n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Mayiladuthurai: 45.84452949236239\n",
      "---------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Starting for city: Thoothukudi \n",
      "\n",
      "Dataset created\n",
      "Model Initialized\n",
      "Starting training model for city: Thoothukudi \n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - loss: 0.3791 - val_loss: 0.1402\n",
      "Epoch 2/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 51ms/step - loss: 0.4353 - val_loss: 0.1062\n",
      "Epoch 3/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - loss: 0.3460 - val_loss: 0.1210\n",
      "Epoch 4/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - loss: 0.6298 - val_loss: 0.1255\n",
      "Epoch 5/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 56ms/step - loss: 0.2811 - val_loss: 0.1320\n",
      "Model trained for city: Thoothukudi \n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Thoothukudi: 41.144447895139415\n",
      "---------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Starting for city: Nagercoil \n",
      "\n",
      "Dataset created\n",
      "Model Initialized\n",
      "Starting training model for city: Nagercoil \n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 63ms/step - loss: 0.2918 - val_loss: 0.1547\n",
      "Epoch 2/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 60ms/step - loss: 0.4047 - val_loss: 0.1534\n",
      "Epoch 3/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 58ms/step - loss: 0.2516 - val_loss: 0.1580\n",
      "Epoch 4/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 60ms/step - loss: 0.2613 - val_loss: 0.1743\n",
      "Epoch 5/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 58ms/step - loss: 0.3021 - val_loss: 0.1564\n",
      "Model trained for city: Nagercoil \n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Nagercoil: 45.81542670214307\n",
      "---------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Starting for city: Thiruvananthapuram \n",
      "\n",
      "Dataset created\n",
      "Model Initialized\n",
      "Starting training model for city: Thiruvananthapuram \n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - loss: 0.3638 - val_loss: 0.2716\n",
      "Epoch 2/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 53ms/step - loss: 0.3041 - val_loss: 0.2726\n",
      "Epoch 3/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 53ms/step - loss: 0.2748 - val_loss: 0.2697\n",
      "Epoch 4/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 53ms/step - loss: 0.2536 - val_loss: 0.2737\n",
      "Epoch 5/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 55ms/step - loss: 0.3393 - val_loss: 0.2857\n",
      "Model trained for city: Thiruvananthapuram \n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Thiruvananthapuram: 53.65594672750044\n",
      "---------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Starting for city: Kollam \n",
      "\n",
      "Dataset created\n",
      "Model Initialized\n",
      "Starting training model for city: Kollam \n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 62ms/step - loss: 0.3154 - val_loss: 0.2622\n",
      "Epoch 2/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 62ms/step - loss: 0.3003 - val_loss: 0.2486\n",
      "Epoch 3/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 57ms/step - loss: 0.2906 - val_loss: 0.2492\n",
      "Epoch 4/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 57ms/step - loss: 0.3535 - val_loss: 0.2511\n",
      "Epoch 5/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 55ms/step - loss: 0.2895 - val_loss: 0.2442\n",
      "Model trained for city: Kollam \n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step\n",
      "MSE for Kollam: 47.935256245254074"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Starting for city: Kochi \n",
      "\n",
      "Dataset created\n",
      "Model Initialized\n",
      "Starting training model for city: Kochi \n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 51ms/step - loss: 0.6880 - val_loss: 0.5183\n",
      "Epoch 2/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 51ms/step - loss: 0.5912 - val_loss: 0.5332\n",
      "Epoch 3/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 51ms/step - loss: 0.6004 - val_loss: 0.5309\n",
      "Epoch 4/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - loss: 0.5146 - val_loss: 0.5414\n",
      "Epoch 5/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 51ms/step - loss: 0.5194 - val_loss: 0.5296\n",
      "Model trained for city: Kochi \n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Kochi: 74.53864162064924\n",
      "---------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Starting for city: Kozhikode \n",
      "\n",
      "Dataset created\n",
      "Model Initialized\n",
      "Starting training model for city: Kozhikode \n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 51ms/step - loss: 0.6175 - val_loss: 0.5192\n",
      "Epoch 2/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - loss: 0.4836 - val_loss: 0.4729\n",
      "Epoch 3/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 50ms/step - loss: 0.6136 - val_loss: 0.4941\n",
      "Epoch 4/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 54ms/step - loss: 0.6399 - val_loss: 0.4855\n",
      "Epoch 5/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 55ms/step - loss: 0.5054 - val_loss: 0.4729\n",
      "Model trained for city: Kozhikode \n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Kozhikode: 75.87751086632214\n",
      "---------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Starting for city: Kannur \n",
      "\n",
      "Dataset created\n",
      "Model Initialized\n",
      "Starting training model for city: Kannur \n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 54ms/step - loss: 0.7474 - val_loss: 0.6894\n",
      "Epoch 2/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - loss: 0.6289 - val_loss: 0.6794\n",
      "Epoch 3/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - loss: 0.6707 - val_loss: 0.6704\n",
      "Epoch 4/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 54ms/step - loss: 0.5846 - val_loss: 0.6559\n",
      "Epoch 5/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - loss: 0.5587 - val_loss: 0.6770\n",
      "Model trained for city: Kannur \n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Kannur: 84.65461741984141\n",
      "---------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Starting for city: Visakhapatnam \n",
      "\n",
      "Dataset created\n",
      "Model Initialized\n",
      "Starting training model for city: Visakhapatnam \n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - loss: 0.3333 - val_loss: 0.4245\n",
      "Epoch 2/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - loss: 0.4140 - val_loss: 0.4910\n",
      "Epoch 3/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 52ms/step - loss: 0.2660 - val_loss: 0.4710\n",
      "Epoch 4/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 53ms/step - loss: 0.3351 - val_loss: 0.4535\n",
      "Epoch 5/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 54ms/step - loss: 0.3520 - val_loss: 0.4463\n",
      "Model trained for city: Visakhapatnam \n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Visakhapatnam: 101.65358779357166\n",
      "---------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Starting for city: Nellore \n",
      "\n",
      "Dataset created\n",
      "Model Initialized\n",
      "Starting training model for city: Nellore \n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 52ms/step - loss: 0.2892 - val_loss: 0.2000\n",
      "Epoch 2/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - loss: 0.2477 - val_loss: 0.2147\n",
      "Epoch 3/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 54ms/step - loss: 0.2779 - val_loss: 0.1958\n",
      "Epoch 4/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 63ms/step - loss: 0.3114 - val_loss: 0.1972\n",
      "Epoch 5/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 77ms/step - loss: 0.2724 - val_loss: 0.1982\n",
      "Model trained for city: Nellore \n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Nellore: 42.39770123982777\n",
      "---------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Starting for city: Mangaluru \n",
      "\n",
      "Dataset created\n",
      "Model Initialized\n",
      "Starting training model for city: Mangaluru \n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 70ms/step - loss: 0.7181 - val_loss: 0.5721\n",
      "Epoch 2/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 72ms/step - loss: 0.4764 - val_loss: 0.5511\n",
      "Epoch 3/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 72ms/step - loss: 0.4857 - val_loss: 0.5504\n",
      "Epoch 4/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 71ms/step - loss: 0.4943 - val_loss: 0.5895\n",
      "Epoch 5/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 66ms/step - loss: 0.5169 - val_loss: 0.5805\n",
      "Model trained for city: Mangaluru \n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Mangaluru: 101.44290100773392\n",
      "---------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Starting for city: Udupi \n",
      "\n",
      "Dataset created\n",
      "Model Initialized\n",
      "Starting training model for city: Udupi \n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 67ms/step - loss: 0.6551 - val_loss: 0.6274\n",
      "Epoch 2/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 78ms/step - loss: 0.6196 - val_loss: 0.5994\n",
      "Epoch 3/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 74ms/step - loss: 0.6152 - val_loss: 0.5802\n",
      "Epoch 4/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 73ms/step - loss: 0.5901 - val_loss: 0.5811\n",
      "Epoch 5/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 73ms/step - loss: 0.6024 - val_loss: 0.5984\n",
      "Model trained for city: Udupi \n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Udupi: 95.0481613397193\n",
      "---------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Starting for city: Mumbai \n",
      "\n",
      "Dataset created\n",
      "Model Initialized\n",
      "Starting training model for city: Mumbai \n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 70ms/step - loss: 0.6024 - val_loss: 0.3836\n",
      "Epoch 2/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 81ms/step - loss: 0.4396 - val_loss: 0.3838\n",
      "Epoch 3/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 73ms/step - loss: 0.6386 - val_loss: 0.3909\n",
      "Epoch 4/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 68ms/step - loss: 0.4836 - val_loss: 0.4038\n",
      "Epoch 5/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 67ms/step - loss: 0.7210 - val_loss: 0.4382\n",
      "Model trained for city: Mumbai \n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Mumbai: 86.91059132609318\n",
      "---------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Starting for city: Daman \n",
      "\n",
      "Dataset created\n",
      "Model Initialized\n",
      "Starting training model for city: Daman \n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 70ms/step - loss: 0.5045 - val_loss: 0.3161\n",
      "Epoch 2/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 70ms/step - loss: 0.4758 - val_loss: 0.3119\n",
      "Epoch 3/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 67ms/step - loss: 0.4354 - val_loss: 0.3319\n",
      "Epoch 4/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 69ms/step - loss: 0.4451 - val_loss: 0.3061\n",
      "Epoch 5/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 62ms/step - loss: 0.4892 - val_loss: 0.3719\n",
      "Model trained for city: Daman \n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Daman: 157.64084499328848\n",
      "---------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Starting for city: Alappuzha \n",
      "\n",
      "Dataset created\n",
      "Model Initialized\n",
      "Starting training model for city: Alappuzha \n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 68ms/step - loss: 0.4658 - val_loss: 0.3052\n",
      "Epoch 2/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 59ms/step - loss: 0.3983 - val_loss: 0.3136\n",
      "Epoch 3/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 57ms/step - loss: 0.4113 - val_loss: 0.3237\n",
      "Epoch 4/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 57ms/step - loss: 0.3355 - val_loss: 0.3050\n",
      "Epoch 5/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 56ms/step - loss: 0.3958 - val_loss: 0.3077\n",
      "Model trained for city: Alappuzha \n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Alappuzha: 46.45887610019766\n",
      "---------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Starting for city: Kakinada \n",
      "\n",
      "Dataset created\n",
      "Model Initialized\n",
      "Starting training model for city: Kakinada \n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - loss: 0.3444 - val_loss: 0.5153\n",
      "Epoch 2/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 57ms/step - loss: 0.4768 - val_loss: 0.4100\n",
      "Epoch 3/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 56ms/step - loss: 0.7008 - val_loss: 0.3681\n",
      "Epoch 4/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 58ms/step - loss: 0.3435 - val_loss: 0.3579\n",
      "Epoch 5/5\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 56ms/step - loss: 0.3129 - val_loss: 0.3589\n",
      "Model trained for city: Kakinada \n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Kakinada: 72.67869352594961\n",
      "---------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for city in weather_df['city_name'].unique():\n",
    "\n",
    "    print(f\"Starting for city: {city} \\n\")\n",
    "    city_weather_df = split_dataframe(df=weather_df, city_name=city, scaler=scaler)\n",
    "\n",
    "    X, y = create_sequence(df=city_weather_df, sequence_length=sequence_length)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(f\"Dataset created\")\n",
    "\n",
    "    model = LSTMModelV2(input_size=sequence_length, hidden_size=8, output_size=1)\n",
    "    print(f\"Model Initialized\")\n",
    "\n",
    "    print(f\"Starting training model for city: {city} \\n\")\n",
    "    history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.1)\n",
    "    print(f\"Model trained for city: {city} \\n\")\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = scaler.inverse_transform(y_pred)\n",
    "    y_test = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "    print(f\"MSE for {city}: {mean_squared_error(y_test, y_pred)}\")\n",
    "\n",
    "    model.save(f'../models/{city}_model.h5')\n",
    "\n",
    "    print(\"---------------------------------------------------------------\\n\")\n",
    "    print(\"---------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">40,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_11 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m40,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,619</span> (162.58 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m41,619\u001b[0m (162.58 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,617</span> (162.57 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m41,617\u001b[0m (162.57 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"models/Chennai_model.h5\")\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
